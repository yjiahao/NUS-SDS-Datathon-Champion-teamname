{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas \n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install scikit-optimize\n",
    "%pip install seaborn\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .csv file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "filepath = \"./data/catA_train.csv\" \n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###...code...###\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy as geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('./data/catA_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 5 rows of data\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types of each column\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of data\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "df2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out rows where latitude or longitude are null values\n",
    "\n",
    "df2[df2['LATITUDE'].isnull() | df2['LONGITUDE'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Square Footage as values are all NULL\n",
    "df2.drop(columns = [\"Square Footage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes rows without either lat or long coordinates, since they form a small percentage of our dataset\n",
    "df2 = df2.dropna(subset=[\"LATITUDE\", \"LONGITUDE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# interpolate the NaN values for the columns using KNNImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "\n",
    "df2[['Year Found', 'Employees (Single Site)', 'Employees (Domestic Ultimate Total)', 'Employees (Global Ultimate Total)']]\\\n",
    "= imputer.fit_transform(df2[['Year Found', 'Employees (Single Site)', 'Employees (Domestic Ultimate Total)', 'Employees (Global Ultimate Total)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing inactive companies\n",
    "df2 = df2[df2['Company Status (Active/Inactive)'] == 'Active']\n",
    "\n",
    "#format SIC code as strings\n",
    "df2[\"SIC Code\"] = df2[\"SIC Code\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation matrix between variables\n",
    "\n",
    "numerical_df = df2.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Create a correlation matrix\n",
    "correlation_matrix = numerical_df.corr()\n",
    "\n",
    "# Assuming correlation_matrix is your correlation matrix\n",
    "correlation_df = pd.DataFrame(correlation_matrix)\n",
    "\n",
    "# Print or use the correlation DataFrame as needed\n",
    "correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for consistency between SIC Code and Industry\n",
    "sic_to_industry_mapping = {}\n",
    "for index, row in df2.iterrows():\n",
    "    sic_code = row['SIC Code']\n",
    "    industry = row['Industry']\n",
    "    if sic_code not in sic_to_industry_mapping:\n",
    "        sic_to_industry_mapping[sic_code] = industry\n",
    "    else:\n",
    "        # If the SIC code is already in the mapping, check if the mapped industry is the same\n",
    "        if sic_to_industry_mapping[sic_code] != industry:\n",
    "            print(f\"Warning: SIC code {sic_code} maps to multiple industries: {sic_to_industry_mapping[sic_code]} and {industry}\")\n",
    "\n",
    "# Check for duplicates in the mapped industries\n",
    "mapped_industries = list(sic_to_industry_mapping.values())\n",
    "duplicated_industries = [industry for industry in mapped_industries if mapped_industries.count(industry) > 1]\n",
    "\n",
    "if len(duplicated_industries) == 0:\n",
    "    print(\"None of the mapped industries appear more than once.\")\n",
    "else:\n",
    "    print(\"The following mapped industries appear more than once:\")\n",
    "    print(duplicated_industries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Photographic Equipment and Supplies have two codes of 3861 and 5043\n",
    "\n",
    "Opthalmic Goods have two codes of 3851 and 5048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between 8-Digit SIC Codes and descriptions (industries)\n",
    "sic_to_description_mapping = {}\n",
    "for index, row in df2.iterrows():\n",
    "    sic_code = row['8-Digit SIC Code']\n",
    "    description = row['8-Digit SIC Description']\n",
    "    if sic_code not in sic_to_description_mapping:\n",
    "        sic_to_description_mapping[sic_code] = description\n",
    "    else:\n",
    "        # If the SIC code is already in the mapping, check if the mapped description is the same\n",
    "        if sic_to_description_mapping[sic_code] != description:\n",
    "            print(f\"Warning: SIC code {sic_code} maps to multiple descriptions: {sic_to_description_mapping[sic_code]} and {description}\")\n",
    "\n",
    "# Check for duplicates in the mapped descriptions\n",
    "mapped_descriptions = list(sic_to_description_mapping.values())\n",
    "duplicated_descriptions = [description for description in mapped_descriptions if mapped_descriptions.count(description) > 1]\n",
    "\n",
    "if len(duplicated_descriptions) == 0:\n",
    "    print(\"None of the mapped descriptions appear more than once.\")\n",
    "else:\n",
    "    print(\"The following mapped descriptions appear more than once:\")\n",
    "    print(duplicated_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#industry by domestic sales\n",
    "import matplotlib.pyplot as plt\n",
    "# Group the data by 'Industry' and calculate total sales for each industry\n",
    "industry_sales = df2.groupby('Industry')['Sales (Domestic Ultimate Total USD)'].mean()\n",
    "\n",
    "# Sort industries by total sales in descending order\n",
    "richest_industries = industry_sales.sort_values(ascending=False)\n",
    "\n",
    "# Plot the richest industries using a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "richest_industries.head(10).plot(kind='bar', color='skyblue')\n",
    "plt.title(label = 'Top 10 Richest Industries by Average Domestic Total Sales')\n",
    "plt.xlabel('Industry')\n",
    "plt.ylabel('Total Sales (USD)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a bar chart of the top 10 richest industries by Average Domestic Sales. Petroleum Bulk Stations And Terminals have the highest average domestic sales by an extremely large margin, followed by cordage and twine and then petroleum refining. This bar chart serves to show which industries have the highest sales in Singapore, and which industry is the most profitable in Singapore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#industry by global sales\n",
    "import matplotlib.pyplot as plt\n",
    "# Group the data by 'Industry' and calculate total sales for each industry\n",
    "industry_sales = df2.groupby('Industry')['Sales (Global Ultimate Total USD)'].mean()\n",
    "\n",
    "# Sort industries by total sales in descending order\n",
    "richest_industries = industry_sales.sort_values(ascending=False)\n",
    "\n",
    "# Plot the richest industries using a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "richest_industries.head(10).plot(kind='bar', color='skyblue')\n",
    "plt.title('Top 10 Richest Industries by Average Global Total Sales')\n",
    "plt.xlabel('Industry')\n",
    "plt.ylabel('Total Sales (USD)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a bar chart of the top 10 Richest Industries by Average Global Total Sales. Petroleum Refining is the highest, followed by Plastic Bottles and then Air Courier Services. The gap between Petroleum Refining and Plastic Bottles is no where near as large as the gap between Petroleum Bulk Stations And Terminals for average domestic sales. This bar chart serves to show which industries have the highest sales in the world, and which industry is the most profitable in Singapore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domestic sales by entity type\n",
    "\n",
    "domestic_by_entity = df2.groupby('Entity Type')['Sales (Domestic Ultimate Total USD)'].mean()\n",
    "\n",
    "# sort highest earning entities\n",
    "richest_entity = domestic_by_entity.sort_values(ascending = False)\n",
    "\n",
    "# plot bar graph\n",
    "plt.figure(figsize = (10,8))\n",
    "bp = richest_entity.plot(kind = \"bar\", color = \"skyblue\", )\n",
    "\n",
    "plt.xlabel('Entity Type')\n",
    "plt.ylabel('Total Sales (USD)')\n",
    "plt.title(\"Average Sales (Domestic Ultimate Total USD) by Entity Type\")\n",
    "plt.xticks(rotation = 0)\n",
    "for bar in bp.patches:\n",
    "  bp.annotate(format(bar.get_height(), '.2f'),\n",
    "              (bar.get_x() + bar.get_width() / 2,\n",
    "                    bar.get_height()), ha='center', va='center',\n",
    "                   size=8, xytext=(0, 8),\n",
    "                   textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the bar graph of average sales by domestic ultimate total USD by entity type. This is to identify which industry has the highest domestic sale. Subsidiary has the highest, followed closely by Branch, and then a sharp decrease in sales from Branch to Independent, and then followed closely by Parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global sales by entity type\n",
    "\n",
    "global_by_entity = df2.groupby('Entity Type')['Sales (Global Ultimate Total USD)'].mean()\n",
    "\n",
    "# sort highest earning entities\n",
    "richest_global_entity = global_by_entity.sort_values(ascending = False)\n",
    "\n",
    "# plot bar graph\n",
    "plt.figure(figsize = (10,8))\n",
    "bp2 = richest_global_entity.plot(kind = \"bar\", color = \"skyblue\", )\n",
    "\n",
    "plt.xlabel('Entity Type')\n",
    "plt.ylabel('Total Sales (USD)')\n",
    "plt.title(\"Average Sales (Global Ultimate Total USD) by Entity Type\")\n",
    "plt.xticks(rotation = 0)\n",
    "for bar in bp2.patches:\n",
    "  bp2.annotate(format(bar.get_height(), '.2f'),\n",
    "              (bar.get_x() + bar.get_width() / 2,\n",
    "                    bar.get_height()), ha='center', va='center',\n",
    "                   size=8, xytext=(0, 8),\n",
    "                   textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the bar graph of average sales by global ultimate total USD by entity type. This is to identify which industry has the highest sales internationally. Independent has the highest, followed closely by Subsidiary, and then a sharp decrease in sales from Branch to Independent, and then followed closely by Parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map latitude and longitude on a scatterplot, with opacity indicating Sales (Domestic Ultimate Total USD)\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "norm = LogNorm()\n",
    "\n",
    "# create new variable Region\n",
    "conditions = [((df2[\"LATITUDE\"]) > 1.3667) & ((df2[\"LONGITUDE\"]) > 103.8),\n",
    "              ((df2[\"LATITUDE\"]) > 1.3667) & ((df2[\"LONGITUDE\"]) <= 103.8),\n",
    "              ((df2[\"LATITUDE\"]) <= 1.3667) & ((df2[\"LONGITUDE\"]) > 103.8),\n",
    "              ((df2[\"LATITUDE\"]) <= 1.3667) & ((df2[\"LONGITUDE\"]) <= 103.8)]\n",
    "\n",
    "values = [\"North-East\", \"South-East\", \"North-West\", \"South-West\"]\n",
    "\n",
    "df2['Region'] = np.select(conditions, values)\n",
    "print(df2[\"Region\"].value_counts())\n",
    "#Find top 10 highest earning industries in terms\n",
    "total_industry_sales = df2.groupby('Industry')['Sales (Global Ultimate Total USD)'].sum()\n",
    "top10_richest_industries = total_industry_sales.sort_values(ascending=False).head(10)\n",
    "\n",
    "#Assigning colours to the top 10 industries\n",
    "ten_colours = sns.color_palette(\"Set2\", n_colors = 10)\n",
    "colourmap = dict(zip(top10_richest_industries.index, ten_colours))\n",
    "\n",
    "#filter for rows with industries in the top 10\n",
    "location_data = df2[df2[\"Industry\"].isin(top10_richest_industries.index.to_list())]\n",
    "\n",
    "#plot a scatterplot of longitude and latitude, with the opacity indicating global sales amount, colour indicating industry\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.scatter(location_data[\"LATITUDE\"], location_data[\"LONGITUDE\"], \\\n",
    "            alpha = norm(location_data[\"Sales (Global Ultimate Total USD)\"]),\\\n",
    "            c = location_data[\"Industry\"].map(colourmap))\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Longitude\")\n",
    "plt.title(\"Map and Sales (Global Ultimate Total USD) of Companies in Top 10 Industries by Sales (Global Ultimate Total USD)\")\n",
    "\n",
    "#legend\n",
    "\n",
    "legend_labels = location_data[\"Industry\"].unique()\n",
    "legend_handles = [plt.Line2D([0], [0], marker='o', color='w', label=industry,\n",
    "                              markerfacecolor=colourmap[industry], markersize=4) for industry in legend_labels]\n",
    "plt.legend(handles = legend_handles, title='Industry', prop={'size': 5}, loc='upper left', bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a distribution of companies in the top 10 industries by sum of global sales on the map of Singapore. The colour identifies each industry and the opacity indicates the amount of sales per company. Most of the companies in Singapore are under offices of holding companies not elsewhere classified. Most of the higher earning companies are in the NorthWest region of Singapore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(\n",
    "    x=df2['Employees (Domestic Ultimate Total)']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the companies employ between 10k to 20k employees, with with only a few companies having enough resources to hire between 20k to 80k employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df2[df2['Employees (Domestic Ultimate Total)'] > 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(\n",
    "    data=df_copy,\n",
    "    x='Employees (Domestic Ultimate Total)',\n",
    "    fill=True,\n",
    "    kde=True,\n",
    "    bins=5,\n",
    "    stat='percent'\n",
    ")\n",
    "\n",
    "plt.title('Histogram of Employees (Domestic Ultimate Total)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 50% of companies hire lesser than 35k, with only 10% of companies hiring more than 65k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.boxplot(\n",
    "    column='Employees (Global Ultimate Total)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This boxplot shows that majority of companies higher lesser than 1 million employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(\n",
    "    data=df2,\n",
    "    x='Employees (Global Ultimate Total)',\n",
    "    log_scale=True\n",
    ")\n",
    "\n",
    "plt.title('KDE plot of Employees (Global Ultimate Total)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2.boxplot(\n",
    "    column='Sales (Domestic Ultimate Total USD)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(\n",
    "    data=df2,\n",
    "    x='Sales (Domestic Ultimate Total USD)',\n",
    "    log_scale=True\n",
    ")\n",
    "\n",
    "plt.title('KDE plot of Sales (Domestic Ultimate Total USD)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.boxplot(\n",
    "    column='Employees (Single Site)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.boxplot(\n",
    "    column='Employees (Domestic Ultimate Total)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.boxplot(\n",
    "    column='Is Domestic Ultimate'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.boxplot(\n",
    "    column='Is Global Ultimate'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domestic_total_by_industry = df2.groupby('Industry')['Sales (Domestic Ultimate Total USD)'].sum()\n",
    "#print(domestic_total_by_industry)\n",
    "\n",
    "# Filter DataFrame for companies considered as domestic ultimate\n",
    "domestic_ultimate_df = df2[df2['Is Domestic Ultimate'] == 1]\n",
    "domestic_ultimate_total_by_industry = domestic_ultimate_df.groupby('Industry')['Sales (Domestic Ultimate Total USD)'].sum()\n",
    "\n",
    "\n",
    "new_table = pd.concat([domestic_total_by_industry, domestic_ultimate_total_by_industry[1:]], axis=1)\n",
    "new_table.columns = ['Total Sales', 'Domestic Ultimate Total Sales']\n",
    "#print(new_table.head(5))\n",
    "# Calculate proportion\n",
    "new_table[\"proportion contributed by domestic ultimate\"] = new_table[\"Domestic Ultimate Total Sales\"]/new_table[\"Total Sales\"]\n",
    "print(new_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_total_by_industry = df2.groupby('Industry')['Sales (Global Ultimate Total USD)'].sum()\n",
    "#print(domestic_total_by_industry)\n",
    "\n",
    "# Filter DataFrame for companies considered as domestic ultimate\n",
    "global_ultimate_df = df2[df2['Is Global Ultimate'] == 1]\n",
    "global_ultimate_total_by_industry = global_ultimate_df.groupby('Industry')['Sales (Global Ultimate Total USD)'].sum()\n",
    "\n",
    "\n",
    "new_table = pd.concat([global_total_by_industry, global_ultimate_total_by_industry[1:]], axis=1)\n",
    "new_table.columns = ['Total Sales', 'Global Ultimate Total Sales']\n",
    "#print(new_table.head(5))\n",
    "# Calculate proportion\n",
    "new_table[\"proportion contributed by Global ultimate\"] = new_table[\"Global Ultimate Total Sales\"]/new_table[\"Total Sales\"]\n",
    "print(new_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['LATITUDE', 'LONGITUDE', 'AccountID', 'Company', '8-Digit SIC Code', 'SIC Code', '8-Digit SIC Description', 'Parent Company', 'Employees (Single Site)', 'Employees (Domestic Ultimate Total)', 'Employees (Global Ultimate Total)', 'Square Footage', 'Import/Export Status', 'Fiscal Year End', 'Company Description', 'Domestic Ultimate Company']\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric features\n",
    "numeric_cols = ['Year Found', 'Sales (Domestic Ultimate Total USD)']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df2[numeric_cols] = scaler.fit_transform(df2[['Year Found', 'Sales (Domestic Ultimate Total USD)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "cols_to_label_encode = ['Industry', 'Parent Country', 'Global Ultimate Company', 'Global Ultimate Country', 'Entity Type', 'Ownership Type', 'Company Status (Active/Inactive)', 'Region']\n",
    "\n",
    "# label encode the columns to label encode\n",
    "df2[cols_to_label_encode] = df2[cols_to_label_encode].apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('./data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "df2 = pd.read_csv('./data/cleaned_data.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df2.drop(columns='Sales (Global Ultimate Total USD)'),\n",
    "    df2['Sales (Global Ultimate Total USD)'],\n",
    "    test_size=0.10,\n",
    "    random_state=42\n",
    "  )\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "search_space = {\n",
    "    'loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "    'learning_rate': [0.000001, 0.0001, 0.1, 1, 10],\n",
    "    'n_estimators': [50, 100, 125, 150, 175, 200, 225, 250, 275, 300],\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'min_samples_split': [10, 50, 100, 125, 150, 200, 250, 300, 350, 400],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 60, 70]\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    GradientBoostingRegressor(),\n",
    "    search_space,\n",
    "    n_iter=5,\n",
    "    verbose=3,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = GradientBoostingRegressor(\n",
    "    criterion='squared_error',\n",
    "    learning_rate=0.1,\n",
    "    loss='squared_error',\n",
    "    max_depth=8,\n",
    "    min_samples_split=300,\n",
    "    n_estimators=250\n",
    ")\n",
    "\n",
    "model_final.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_final.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the base model to an HDF5 file\n",
    "joblib.dump(model_final, 'final_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform. \n",
    "    \n",
    "All relevant code MUST be included in this function.'''\n",
    "\n",
    "    result = [] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_csv(filepath)\n",
    "test_df = test_df.drop(columns=['Sales (Domestic Ultimate Total USD)'])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
